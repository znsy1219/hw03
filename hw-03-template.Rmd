---
title: "hw-03"
author: "Nanshuyuan Zhang(s2516281)"
date: "`r Sys.Date()`"
output: html_document
---



```{r setup, include=FALSE}
## **DO NOT EDIT THIS CODE CHUNK**
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
```


## Data load and preparation before modelling

```{r read_data}
gss16<-read.csv("data/gss16.csv")
```

#### Cleaning and selecting columns

```{r}
gss16_advfront <- gss16 %>%
  select(advfront, emailhr, educ, polviews, wrkstat) %>%
  drop_na()
```

#### Re-levelling `advfront`

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    advfront = case_when(
      advfront == "Strongly agree" ~ "Agree",
      advfront == "Agree" ~ "Agree",
      TRUE ~ "Not agree"
    ),
    advfront = fct_relevel(advfront, "Not agree", "Agree")
  )
```

#### Re-levelling `polviews`

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    polviews = case_when(
      str_detect(polviews, "[Cc]onservative") ~ "Conservative",
      str_detect(polviews, "[Ll]iberal") ~ "Liberal",
      TRUE ~ polviews
    ),
    polviews = fct_relevel(polviews, "Conservative", "Moderate", "Liberal")
  )
```

#### Creating a new `fulltime` variable

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(fulltime = ifelse(wrkstat == "Working fulltime",TRUE,FALSE))
```


## Exercise 1: Create a linear regression model

#### Exercise 1 (a)

```{r}

model <- lm(emailhr ~ educ + fulltime, data = gss16_advfront)

summary(model)


glance(model)


```

p-value is a low value, indicates that the model is statistically significant, meaning the predictors is contributing to explaining the variance in emailhr.
The R squared value after adjustment decreased.
r.squared=0.08517216: This means that 8.5% of the variance in emailhr is explained by educ and fulltime.
adj.r.squared =0.08360701: This indicates that the model is a good fit without overfitting.


#### Exercise 1 (b)

```{r}

print(glance(model))

par(mfrow = c(2, 2))  
plot(model)


ggplot(gss16_advfront, aes(x = educ, y = emailhr, color = fulltime)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship Between Education, Fulltime Status, and Email Hours",
       x = "Education (Years)", y = "Email Hours per Week",
       color = "Full-time Status") +
  theme_minimal()


```

Residuals vs Fitted plot shows no clear pattern, this suggests that the linearity assumption is satisfied.
The Normal Q-Q plot, the high theoretical quantiles do not fit in the straight line, which indicates that normality assumption is not satisfied.
In the Scale-Location plot, the points are randomly scattered and not funnel-shaped, which indicates that the homoscedasticity is satisfied.
In Residuals vs Leverage, there is no influential points are visible.
I think this model is not a good fit for these data. It is necessary to apply transformations to the predictors or consider alternative models.
## Exercise 2: Create a workflow to fit a model

```{r split-data}
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
```

#### Exercise 2 (a)

```{r}

gss16_rec_1 <- recipe(advfront ~ educ, data = gss16_train)

gss16_mod_1 <- logistic_reg() %>%
  set_engine("glm")

gss16_wflow_1 <- workflow() %>%
  add_recipe(gss16_rec_1) %>%
  add_model(gss16_mod_1)

```

The higher the number of years of education, the more likely a person is to support funding for scientific research.

#### Exercise 2 (b)

```{r}
# replace this with your code
```

The response variable advfront is binary. Logistic regression is a standard method for binary classification. Also it is a computationally efficient model.
Logistic regression fits the requirements of this task (binary classification), and is computationally efficient. While more complex models like decision trees or random forests could be used, they would add unnecessary complexity and reduce interpretability for this specific problem.


#### Exercise 2 (c)

```{r}
gss16_fit_1 <- fit(gss16_wflow_1, data = gss16_train)

tidy(gss16_fit_1)

```

Intercept: When educ = 0, the log-odds of agreeing with the statement are -0.3750807.
educ: For every additional year of education, the log-odds of agreeing increase by 0.1497668.
Significance: Both coefficients are statistically significant (p.value < 0.5).

Model Equation: log-odds(advfront="Agree")=-0.3750807+0.1497668â‹…educ

## Exercise 3: Logistic regression with single predictor

#### Exercise 3 (a)

```{r}

gss16_predictions <- predict(gss16_fit_1, gss16_test, type = "prob") %>%
  bind_cols(gss16_test)

glimpse(gss16_predictions)

gss16_roc <- roc_curve(gss16_predictions, truth = advfront, .pred_Agree)

autoplot(gss16_roc) +
  labs(
    title = "ROC Curve for Logistic Regression Model",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    caption = "Evaluating the model's ability to predict 'Agree'"
  ) +
  theme_minimal()

```

*Your answer here*

## Exercise 4: Logistic regression modelling and interpretation

#### Exercise 4 (a)

```{r}
```

*Your answer here*

#### Exercise 3 (b)

```{r}
gss16_predictions <- gss16_predictions %>%
  mutate(
    .pred_class = factor(if_else(.pred_Agree >= 0.85, "Agree", "Not agree"), 
      levels = levels(advfront) ) ) 
gss16_predictions %>% 
  
  sens(truth = advfront, estimate = .pred_class)
glimpse(gss16_predictions)
gss16_predictions %>% 
  
  spec(truth = advfront, estimate = .pred_class)

```

*Your answer here*

## Exercise 4: Logistic regression modelling and interpretation

#### Exercise 4 (a)

```{r}
# replace this with your code
```

*Your answer here*

  
#### Exercise 4 (b)
  
```{r}
# replace this with your code
```

*Your answer here*

#### Exercise 4 (c) 

```{r}
# replace this with your code
```

*Your answer here*

